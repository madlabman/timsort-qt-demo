<html>
	<body>
	<div class="content html_format">
    	<b>Timsort</b>, в отличии от всяких там «пузырьков» и «вставок», штука относительно новая — изобретен был в 2002 году Тимом Петерсом (в честь него и назван). С тех пор он уже стал стандартным алгоритмом сортировки в Python, OpenJDK 7 и Android JDK 1.5. А чтобы понять почему — достаточно взглянуть на вот эту табличку из Википедии.<br/>
 <img src="table_wiki.png"/><br/>
<br/>
Среди, на первый взгляд, огромного выбора в таблице есть всего 7 адекватных алгоритмов (со сложностью <i>O(n logn)</i> в среднем и худшем случае), среди которых только 2 могут похвастаться стабильностью и сложностью <i>O(n)</i> в лучшем случае. Один из этих двух — это давно и хорошо всем известная «Сортировка с помощью двоичного дерева». А вот второй как-раз таки Timsort.<br/>
<br/>
Алгоритм построен на той идее, что в реальном мире сортируемый массив данных часто содержат в себе упорядоченные (не важно, по возрастанию или по убыванию) подмассивы. Это и вправду часто так. На таких данных Timsort рвёт в клочья все остальные алгоритмы. <br/>
 <a name="habracut"></a><br/>
 <h4>Сразу к сути</h4><br/>
 Не ждите тут каких-то сложных математических открытий. Дело в том, что на самом деле Timsort — это не полностью самостоятельный алгоритм, а гибрид, эффективная комбинация нескольких других алгоритмов, приправленная собственными идеями. Очень коротко суть алгоритма можно объяснить так:<br/>
 <ol>
<li>По специальному алгоритму разделяем входной массив на подмассивы.</li>
<li>Сортируем каждый подмассив обычной сортировкой вставками.</li>
<li>Собираем отсортированные подмассивы в единый массив с помощью модифицированной сортировки слиянием.</li>
</ol>Дьявол, как всегда, скрывается в деталях, а именно в алгоритме из пункта 1 и модификации сортировки слиянием из пункта 3.<br/>
<br/>
<h4>Алгоритм</h4><br/>
<h5>Используемые понятия</h5><ul>
<li><b>N</b> — размер входного массива</li>
<li><b>run</b> — упорядоченный подмассив во входном массиве. Причём упорядоченный либо нестрого по возрастанию, либо строго по убыванию. Т.е или «a0 &lt;= a1 &lt;= a2 &lt;= ...», либо «a0 &gt; a1 &gt; a2 &gt; ...»</li>
<li><b>minrun</b> — как было сказано выше, на первом шаге алгоритма входной массив будет поделен на подмассивы. <b>minrun</b> — это минимальный размер такого подмассива. Это число рассчитывается по определённой логике из числа <b>N</b>.</li>
</ul><br/>
<img src="arrays.png"/><br/>
 <br/>
<h5>Шаг 0. Вычисление <b>minrun</b>.</h5><br/>
 Число <b>minrun</b> определяется на основе <b>N</b> исходя из следующих принципов:<br/>
 <ol>
<li>Оно не должно быть слишком большим, поскольку к подмассиву размера <b>minrun</b> будет в дальнейшем применена сортировка вставками, а она эффективна только на небольших массивах</li>
<li>Оно не должно быть слишком маленьким, поскольку чем меньше подмассив — тем больше итераций слияния подмассивов придётся выполнить на последнем шаге алгоритма.</li>
<li>Хорошо бы, чтобы <b>N \ minrun</b> было степенью числа 2 (или близким к нему). Это требование обусловлено тем, что алгоритм слияния подмассивов наиболее эффективно работает на подмассивах примерно равного размера.</li>
</ol>В этом месте автор алгоритма ссылается на собственные эксперименты, показавшие, что при <b>minrun</b>&gt; 256 нарушается пункт 1, при <b>minrun</b> &lt; 8 — пункт 2 и наиболее эффективно использовать значения из диапазона (32;65). Исключение — если <b>N</b> &lt; 64, тогда <b>minrun</b> = <b>N</b> и timsort превращается в простую сортировку вставкой. В данный момент алгоритм расчёта <b>minrun</b> просто до безобразия: берём старшие 6 бит из <b>N</b> и добавляем единицу, если в оставшихся младших битах есть хотя бы один ненулевой. Примерный код выглядит так:<br/>
 <pre><code class="cpp">	int GetMinrun(int n)
	{
	    int r = 0;           /* станет 1 если среди сдвинутых битов будет хотя бы 1 ненулевой */
	    while (n &gt;= 64) {
	        r |= n & 1;
	        n &gt;&gt;= 1;
	    }
	    return n + r;
	}</code></pre><br/>
 <h5>Шаг 1. Разбиение на подмассивы и их сортировка.</h5><br/>
 Итак, на данном этапе у нас есть входной массив, его размер <b>N</b> и вычисленное число <b>minrun</b>. Алгоритм работы этого шага:<br/>
 <ol>
<li>Ставим указатель текущего элемента в начало входного массива.</li>
<li>Начиная с текущего элемента, ищем во входном массиве <b>run</b> (упорядоченный подмассив). По определению, в этот <b>run</b> однозначно войдет текущий элемент и следующий за ним, а вот дальше — уже как повезет. Если получившийся подмассив упорядочен по убыванию — переставляем элементы так, чтобы они шли по возрастанию (это простой линейный алгоритм, просто идём с обоих концов к середине, меняя элементы местами).</li>
<li>Если размер текущего <b>run'</b>а меньше чем <b>minrun</b> — берём следующие за найденным <b>run</b>-ом элементы в количестве <b>minrun — size(run)</b>. Таким образом, на выходе у нас получается подмассив размером <b>minrun</b> или больше, часть которого (а в идеале — он весь) упорядочена. </li>
<li>Применяем к данному подмассиву сортировку вставками. Так как размер подмассива невелик и часть его уже упорядочена — сортировка работает быстро и эффективно.</li>
<li>Ставим указатель текущего элемента на следующий за подмассивом элемент.</li>
<li>Если конец входного массива не достигнут — переход к пункту 2, иначе — конец данного шага.</li>
</ol><br/>
<h5>Шаг 2. Слияние.</h5><br/>
 На данном этапе у нас имеется входной массив, разбитый на подмассивы, каждый из которых упорядочен. Если данные входного массива были близки к случайным — размер упорядоченных подмассивов близок к <b>minrun</b>, если в данных были упорядоченные диапазоны (а исходя из рекомендаций по применению алгоритма, у нас есть основания на это надеяться) — упорядоченные подмассивы имеют размер, превышающий <b>minrun</b>.<br/>
 Теперь нам нужно объединить эти подмассивы для получения результирующего, полностью упорядоченного массива. Причём по ходу этого объединения нужно выполнить 2 требования:<br/>
 <ol>
<li>Объединять подмассивы примерно равного размера (так получается эффективнее).</li>
<li>Сохранить стабильность алгоритма — т.е. не делать бессмысленных перестановок (например, не менять два последовательно стоящих одинаковых числа местами).</li>
</ol><br/>
 Достигается это таким образом.<br/>
 <ol>
<li>Создаем пустой стек пар &lt;индекс начала подмассива&gt;-&lt;размер подмассива&gt;. Берём первый упорядоченный подмассив.</li>
<li>Добавляем в стек пару данных &lt;индекс начала&gt;-&lt;размер&gt; для текущего подмассива.</li>
<li>Определяем, нужно ли выполнять процедуру слияния текущего подмассива с предыдущими. Для этого проверяется выполнение 2 правил (пусть X, Y и Z — размеры трёх верхних в стеке подмассивов):<br/>
 X &gt; Y + Z<br/>
 Y &gt; Z</li>
<li>Если одно из правил нарушается — массив Y сливается с меньшим из массивов X и Z. Повторяется до выполнения обоих правил или полного упорядочивания данных.</li>
<li>Если еще остались не рассмотренные подмассивы — берём следующий и переходим к пункту 2. Иначе — конец.</li>
</ol><br/>
 Цель этой хитрой процедуры — сохранение баланса. Т.е. изменения будут выглядеть вот так:<br/>
<img src="tim_merge.png"/><br/>
 а значит, размеры подмассивов в стеке эффективны для дальнейшей сортировки слиянием. Представьте себе идеальный случай: у нас есть подмассивы размера 128, 64, 32, 16, 8, 4, 2, 2 (забудем на секунду о наличии требования «размер подмассива &gt;= <b>minrun</b>»). В этом случае никаких слияний не будет выполнятся пока не встретятся 2 последних подмассива, а вот после этого будут выполнены 7 идеально сбалансированных слияний.<br/>
<br/>
<h5>Процедура слияния подмассивов</h5><br/>
 Как Вы помните, на втором шаге алгоритма мы занимаемся слиянием двух подмассивов в один упорядоченный. Мы всегда соединяем 2 последовательных подмассива. Для их слияния используется дополнительная память.<br/>
 <ol>
<li>Создаём временный массив в размере меньшего из соединяемых подмассивов.</li>
<li>Копируем меньший из подмассивов во временный массив</li>
<li>Ставим указатели текущей позиции на первые элементы большего и временного массива.</li>
<li>На каждом следующем шаге рассматриваем значение текущих элементов в большем и временном массивах, берём меньший из них и копируем его в новый отсортированный массив. Перемещаем указатель текущего элемента в массиве, из которого был взят элемент.</li>
<li>Повторяем 4, пока один из массивов не закончится.</li>
<li>Добавляем все элементы оставшегося массива в конец нового массива.</li>
</ol><img src="copy_arr.png"/><br/>
<br/>
<h5>Модификация процедуры слияния подмассивов</h5><br/>
 Всё, вроде бы, хорошо в показанном выше алгоритме слияния. Кроме одного. Представьте себе процедуру слияния двух вот таких массивов:<br/>
 <b>A</b> = {1, 2, 3,..., 9999, 10000}<br/>
 <b>B</b> = { 20000, 20001, ...., 29999, 30000}<br/>
 Вышеуказанная процедура для них, конечно, сработает, но каждый раз на её четвёртом пункте нужно будет выполнить одно сравнение и одно копирование. И того 10000 сравнений и 10000 копирований. Алгоритм Timsort предлагает в этом месте модификацию, которую он называет «галоп». Суть в следующем: <br/>
 <ol>
<li>Начинаем процедуру слияния, как было показано выше.</li>
<li>На каждой операции копирования элемента из временного или большего подмассива в результирующий запоминаем, из какого именно подмассива был элемент.</li>
<li>Если уже некоторое количество элементов (в данной реализации алгоритма это число жестко равно 7) было взято из одного и того же массива — предполагаем, что и дальше нам придётся брать данные из него. Чтобы подтвердить эту идею, мы переходим в режим «галопа», т.е. бежим по массиву-претенденту на поставку следующей большой порции данных бинарным поиском (мы помним, что массив упорядочен и мы имеем полное право на бинарный поиск) текущего элемента из второго соединяемого массива. Бинарный поиск эффективнее линейного, а потому операций поиска будет намного меньше. </li>
<li>Найдя, наконец, момент, когда данные из текущего массива-поставщика нам больше не подходят (или дойдя до конца массива), мы можем, наконец, скопировать их все разом (что может быть эффективнее копирования одиночных элементов).</li>
</ol><br/>
 Возможно, объяснение слегка туманно, попробуем на примере. <br/>
 <b>A</b> = {1, 2, 3,..., 9999, 10000}<br/>
 <b>B</b> = { 20000, 20001, ...., 29999, 30000}<br/>
 <ol>
<li>Первые 7 итераций мы сравниваем числа 1, 2, 3, 4, 5, 6 и 7 из массива <b>A</b> с числом 20000 и, убедившись, что 20000 больше — копируем элементы массива <b>A</b> в результирующий.</li>
<li>Начиная со следующей итерации переходим в режим «галопа»: сравниваем с числом 20000 последовательно элементы 8, 10, 14, 22, 38, n+2^i, ..., 10000 массива <b>A</b>. Как видно, таких сравнение будет намного меньше 10000.</li>
<li>Мы дошли до конца массива <b>A</b> и знаем, что он весь меньше <b>B</b> (мы могли также остановиться где-то посередине). Копируем нужные данные из массива <b>A</b> в результирующий, идём дальше.</li>
</ol><br/>
Вот и весь алгоритм. <br/>

	</body>
</html>








